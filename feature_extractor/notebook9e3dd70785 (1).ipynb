{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import json\n",
    "import skimage.io\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-30T02:11:56.661014Z",
     "iopub.execute_input": "2022-03-30T02:11:56.661920Z",
     "iopub.status.idle": "2022-03-30T02:12:02.614182Z",
     "shell.execute_reply.started": "2022-03-30T02:11:56.661812Z",
     "shell.execute_reply": "2022-03-30T02:12:02.613005Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class OneHotEncoder(object):\n",
    "    def __init__(self, tags):\n",
    "        self.tags = tags\n",
    "        self.dict = {}\n",
    "        for i, tag in enumerate(tags):\n",
    "            self.dict[tag] = i\n",
    "    \n",
    "    def encode(self, tags, max_batch_length=64):\n",
    "        result = [0] * max_batch_length\n",
    "        for tag in tags:\n",
    "            if tag in self.tags:\n",
    "                result[self.dict[tag]] = 1\n",
    "        result = tf.convert_to_tensor(result, dtype=tf.dtypes.int64)\n",
    "        return result\n",
    "    \n",
    "    def decode(self, encoded):\n",
    "        result = []\n",
    "        encoded = encoded.numpy().tolist()\n",
    "        for i, true in enumerate(encoded):\n",
    "            if true:\n",
    "                result.append(self.tags[i])\n",
    "        return result"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T01:52:01.165833Z",
     "iopub.execute_input": "2022-03-30T01:52:01.166138Z",
     "iopub.status.idle": "2022-03-30T01:52:01.184815Z",
     "shell.execute_reply.started": "2022-03-30T01:52:01.166036Z",
     "shell.execute_reply": "2022-03-30T01:52:01.183734Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "base_metadata_path = \"../datasets/archive/danbooru-metadata/danbooru-metadata\"\n",
    "base_image_path = \"../datasets/archive/danbooru-images/danbooru-images\"\n",
    "tags = ['1boy', '1girl', '2girls', '3girls', 'ahoge', 'animal_ears', 'bangs', 'bare_shoulders', 'black_legwear', 'blush', 'boots', 'bow', 'braid', 'breasts', 'cleavage', 'closed_eyes', 'detached_sleeves', 'dress', 'flower', 'food', 'full_body', 'glasses', 'gloves', 'hat', 'heart', 'holding', 'jacket', 'japanese_clothes', 'jewelry', 'large_breasts', 'long_hair', 'long_sleeves', 'male_focus', 'medium_breasts', 'multiple_boys', 'multiple_girls', 'navel', 'necktie', 'one_eye_closed', 'open_mouth', 'panties', 'pantyhose', 'ponytail', 'ribbon', 'school_uniform', 'shirt', 'shoes', 'short_hair', 'simple_background', 'sitting', 'skirt', 'smile', 'solo', 'standing', 'swimsuit', 'sword', 'tail', 'thighhighs', 'twintails', 'underwear', 'very_long_hair', 'weapon', 'white_background', 'wings']\n",
    "encoder = OneHotEncoder(tags)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T01:52:01.186076Z",
     "iopub.execute_input": "2022-03-30T01:52:01.186435Z",
     "iopub.status.idle": "2022-03-30T01:52:01.200547Z",
     "shell.execute_reply.started": "2022-03-30T01:52:01.186391Z",
     "shell.execute_reply": "2022-03-30T01:52:01.199029Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def fix_dim(img):\n",
    "    if len(img.shape) == 3:\n",
    "        return img\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = img\n",
    "    ret[:, :, 1] = img\n",
    "    ret[:, :, 2] = img\n",
    "    return ret"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T01:52:01.202458Z",
     "iopub.execute_input": "2022-03-30T01:52:01.202808Z",
     "iopub.status.idle": "2022-03-30T01:52:01.216368Z",
     "shell.execute_reply.started": "2022-03-30T01:52:01.202774Z",
     "shell.execute_reply": "2022-03-30T01:52:01.215649Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "import tensorflow.keras.preprocessing.image as kimg\n",
    "\n",
    "def load_image(path):\n",
    "    x = kimg.load_image(path)\n",
    "    x = kimg.image_to_array(x)\n",
    "    return resize(fix_dim(x), (384, 384))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def image_gen(batch_size=64, train=True):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "\n",
    "    batcher = get_one()\n",
    "\n",
    "    while True:\n",
    "        x, y = next(batcher)\n",
    "        num = random.randint(0, 19)\n",
    "        if num % 20 == 0 and train: continue\n",
    "        if num % 20 != 0 and (not train): continue\n",
    "\n",
    "        x.append(x)\n",
    "        y.append(y)\n",
    "\n",
    "        if len(x) == batch_size:\n",
    "            yield x, y\n",
    "            x = []\n",
    "            y = []\n",
    "\n",
    "\n",
    "def get_one():\n",
    "    for file in os.listdir(base_metadata_path):\n",
    "        with open(os.path.join(base_metadata_path, file), 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                j = json.loads(line)\n",
    "\n",
    "                # get json fields\n",
    "                image_id = j['id']\n",
    "                ext = j['file_ext']\n",
    "                tags = j['tags']\n",
    "\n",
    "                # get tag names and ids\n",
    "                tag_names = list(map(lambda t: t['name'], tags))\n",
    "\n",
    "                # dir of the image\n",
    "                image_path = str(int(image_id) % 1000).zfill(4)\n",
    "\n",
    "                # path to image\n",
    "                path = os.path.join(base_image_path, image_path, image_id) + f'.{ext}'\n",
    "                # due to the smaller subset, not all images are available (?)\n",
    "                if os.path.exists(path):\n",
    "                    x = load_image(path)\n",
    "                    y = encoder(tag_names)\n",
    "                    yield x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size=32, dim=(384, 384), n_channels=3, n_classes=10, shuffle=True, train=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.validation_data = not train\n",
    "\n",
    "    def __len__(self):\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return next(image_gen(batch_size=self.batch_size, train=self.train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from distutils.version import LooseVersion\n",
    "from skimage import transform\n",
    "\n",
    "def resize(image, output_shape, order=1, mode='constant', cval=0, clip=True,\n",
    "           preserve_range=False, anti_aliasing=False, anti_aliasing_sigma=None):\n",
    "    \"\"\"A wrapper for Scikit-Image resize().\n",
    "\n",
    "    Scikit-Image generates warnings on every call to resize() if it doesn't\n",
    "    receive the right parameters. The right parameters depend on the version\n",
    "    of skimage. This solves the problem by using different parameters per\n",
    "    version. And it provides a central place to control resizing defaults.\n",
    "    \"\"\"\n",
    "    if LooseVersion(skimage.__version__) >= LooseVersion(\"0.14\"):\n",
    "        # New in 0.14: anti_aliasing. Default it to False for backward\n",
    "        # compatibility with skimage 0.13.\n",
    "        return transform.resize(\n",
    "            image, output_shape,\n",
    "            order=order, mode=mode, cval=cval, clip=clip,\n",
    "            preserve_range=preserve_range, anti_aliasing=anti_aliasing,\n",
    "            anti_aliasing_sigma=anti_aliasing_sigma)\n",
    "    else:\n",
    "        return transform.resize(\n",
    "            image, output_shape,\n",
    "            order=order, mode=mode, cval=cval, clip=clip,\n",
    "            preserve_range=preserve_range)\n",
    "\n",
    "def load_image(path):\n",
    "    x = tf.convert_to_tensor(resize(fix_dim(skimage.io.imread(path)), (224, 224)), dtype = tf.dtypes.float32)\n",
    "    return fix_dim(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T01:52:01.21792Z",
     "iopub.execute_input": "2022-03-30T01:52:01.218159Z",
     "iopub.status.idle": "2022-03-30T01:52:01.22981Z",
     "shell.execute_reply.started": "2022-03-30T01:52:01.2181Z",
     "shell.execute_reply": "2022-03-30T01:52:01.228744Z"
    },
    "trusted": true
   },
   "execution_count": 92,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def data(training=True):\n",
    "    random.seed(175069818)\n",
    "    for file in os.listdir(base_metadata_path):\n",
    "        with open(os.path.join(base_metadata_path, file), 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                num = random.randint(0, 19)\n",
    "                if num % 20 == 0 and training: continue\n",
    "                if num % 20 != 0 and (not training): continue\n",
    "                j = json.loads(line)\n",
    "                \n",
    "                # get json fields\n",
    "                image_id = j['id']\n",
    "                ext = j['file_ext']\n",
    "                tags = j['tags']\n",
    "            \n",
    "                # get tag names and ids\n",
    "                tag_names = list(map(lambda t: t['name'], tags))\n",
    "            \n",
    "                # dir of the image\n",
    "                image_path = str(int(image_id) % 1000).zfill(4)\n",
    "            \n",
    "                # path to image\n",
    "                path = os.path.join(base_image_path, image_path, image_id) + f'.{ext}'\n",
    "                # due to the smaller subset, not all images are available\n",
    "                if os.path.exists(path):\n",
    "                    x = load_image(path)\n",
    "                    y = tag_names\n",
    "                    y = encoder.encode(y)\n",
    "                    yield x, y"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T01:52:01.231573Z",
     "iopub.execute_input": "2022-03-30T01:52:01.231841Z",
     "iopub.status.idle": "2022-03-30T01:52:01.243408Z",
     "shell.execute_reply.started": "2022-03-30T01:52:01.231811Z",
     "shell.execute_reply": "2022-03-30T01:52:01.242363Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(data,\n",
    "                                                   output_signature=(\n",
    "                                                       tf.TensorSpec(shape=(224, 224, 3)),\n",
    "                                                       tf.TensorSpec(shape=[64])\n",
    "                                                   )).batch(batch_size=10)\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: data(False),\n",
    "                                                   output_signature=(\n",
    "                                                       tf.TensorSpec(shape=(224, 224, 3)),\n",
    "                                                       tf.TensorSpec(shape=[64])\n",
    "                                                   )).batch(batch_size=10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T01:52:01.245012Z",
     "iopub.execute_input": "2022-03-30T01:52:01.245329Z",
     "iopub.status.idle": "2022-03-30T01:52:01.311201Z",
     "shell.execute_reply.started": "2022-03-30T01:52:01.2453Z",
     "shell.execute_reply": "2022-03-30T01:52:01.31037Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 93,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "train_dataset = DataGenerator(batch_size=64, train=True)\n",
    "valid_dataset = DataGenerator(batch_size=64, train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=\"avg\",\n",
    "    classifier_activation=\"softmax\",\n",
    "    classes=64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=200):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "learning_rate = CustomSchedule(1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Train Step')"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "temp_learning_rate_schedule = CustomSchedule(512)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(300000 / 64, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    198/Unknown - 64s 299ms/step - loss: 62980.6133"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23688/486031854.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mhist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalid_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1382\u001B[0m                 _r=1):\n\u001B[0;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1384\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1385\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2954\u001B[0m       (graph_function,\n\u001B[0;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2957\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2958\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1851\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1852\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1854\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=train_dataset, validation_data=valid_dataset, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}