{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade pip"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:23:44.392484Z",
     "iopub.execute_input": "2022-03-29T12:23:44.393657Z",
     "iopub.status.idle": "2022-03-29T12:24:09.604649Z",
     "shell.execute_reply.started": "2022-03-29T12:23:44.393441Z",
     "shell.execute_reply": "2022-03-29T12:24:09.603552Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tensorflow==2.7.0"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:24:09.607146Z",
     "iopub.execute_input": "2022-03-29T12:24:09.607506Z",
     "iopub.status.idle": "2022-03-29T12:25:21.832455Z",
     "shell.execute_reply.started": "2022-03-29T12:24:09.607460Z",
     "shell.execute_reply": "2022-03-29T12:25:21.831462Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade scikit-image"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:21.834197Z",
     "iopub.execute_input": "2022-03-29T12:25:21.834537Z",
     "iopub.status.idle": "2022-03-29T12:25:35.420433Z",
     "shell.execute_reply.started": "2022-03-29T12:25:21.834482Z",
     "shell.execute_reply": "2022-03-29T12:25:35.419258Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import skimage.io\n",
    "import random\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:35.423107Z",
     "iopub.execute_input": "2022-03-29T12:25:35.423378Z",
     "iopub.status.idle": "2022-03-29T12:25:40.511557Z",
     "shell.execute_reply.started": "2022-03-29T12:25:35.423334Z",
     "shell.execute_reply": "2022-03-29T12:25:40.510853Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class OneHotEncoder(object):\n    def __init__(self, tags):\n        self.tags = tags\n        self.dict = {}\n        for i, tag in enumerate(tags):\n            self.dict[tag] = i\n    \n    def encode(self, tags, max_batch_length=64):\n        result = [0] * max_batch_length\n        for tag in tags:\n            result[self.dict[tag]] = 1\n        result = tf.convert_to_tensor(result, dtype=ty.dtypes.int64)\n        return result\n    \n    def decode(self, encoded):\n        result = []\n        encoded = encoded.numpy().tolist()\n        for i, true in enumerate(encoded):\n            if true:\n                result.append(self.tags[i])\n        return result",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.512678Z",
     "iopub.execute_input": "2022-03-29T12:25:40.513500Z",
     "iopub.status.idle": "2022-03-29T12:25:40.522249Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.513453Z",
     "shell.execute_reply": "2022-03-29T12:25:40.521314Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "base_metadata_path = \"../input/tagged-anime-illustrations/danbooru-metadata/danbooru-metadata\"\nbase_image_path = \"../input/tagged-anime-illustrations/danbooru-images/danbooru-images\"\ntags = ['1boy', '1girl', '2girls', '3girls', 'ahoge', 'animal_ears', 'bangs', 'bare_shoulders', 'black_legwear', 'blush', 'boots', 'bow', 'braid', 'breasts', 'cleavage', 'closed_eyes', 'detached_sleeves', 'dress', 'flower', 'food', 'full_body', 'glasses', 'gloves', 'hat', 'heart', 'holding', 'jacket', 'japanese_clothes', 'jewelry', 'large_breasts', 'long_hair', 'long_sleeves', 'male_focus', 'medium_breasts', 'multiple_boys', 'multiple_girls', 'navel', 'necktie', 'one_eye_closed', 'open_mouth', 'panties', 'pantyhose', 'ponytail', 'ribbon', 'school_uniform', 'shirt', 'shoes', 'short_hair', 'simple_background', 'sitting', 'skirt', 'smile', 'solo', 'standing', 'swimsuit', 'sword', 'tail', 'thighhighs', 'twintails', 'underwear', 'very_long_hair', 'weapon', 'white_background', 'wings']\nencoder = OneHotEncoder(tags)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.523209Z",
     "iopub.execute_input": "2022-03-29T12:25:40.523741Z",
     "iopub.status.idle": "2022-03-29T12:25:40.536960Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.523710Z",
     "shell.execute_reply": "2022-03-29T12:25:40.536163Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def fix_dim(img):\n    if len(img.shape) is 3:\n        return img\n    w, h = img.shape\n    ret = np.empty((w, h, 3), dtype=np.uint8)\n    ret[:, :, 0] = img\n    ret[:, :, 1] = img\n    ret[:, :, 2] = img\n    return ret",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.538388Z",
     "iopub.execute_input": "2022-03-29T12:25:40.539259Z",
     "iopub.status.idle": "2022-03-29T12:25:40.553769Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.539206Z",
     "shell.execute_reply": "2022-03-29T12:25:40.552624Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def load_image(path):\n    x = tf.conver_to_tensor(skimage.io.imread(path), dtype = tf.dtypes.float32)\n    return fix_dim(x)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.555283Z",
     "iopub.execute_input": "2022-03-29T12:25:40.555570Z",
     "iopub.status.idle": "2022-03-29T12:25:40.566034Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.555516Z",
     "shell.execute_reply": "2022-03-29T12:25:40.565289Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def data(training=True):\n    random.seed(175069818)\n    for file in os.listdir(base_metadata_path):\n        with open(os.path.join(base_metadata_path, file), 'r') as f:\n            for i, line in enumerate(f):\n                num = random.randint(0, 19)\n                if num % 20 == 0 and training: continue\n                if num % 20 != 0 and (not training): continue\n                j = json.loads(line)\n                \n                # get json fields\n                image_id = j['id']\n                ext = j['file_ext']\n                tags = j['tags']\n            \n                # get tag names and ids\n                tag_names = list(map(lambda t: t['name'], tags))\n            \n                # dir of the image\n                image_path = str(int(image_id) % 1000).zfill(4)\n            \n                # path to image\n                path = os.path.join(base_image_path, image_path, image_id) + f'.{ext}'\n                # due to the smaller subset, not all images are available\n                if os.path.exists(path):\n                    x = load_image(path)\n                    y = tag_names\n                    y = encoder.encode(y)\n                    yield x, y",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.567159Z",
     "iopub.execute_input": "2022-03-29T12:25:40.567769Z",
     "iopub.status.idle": "2022-03-29T12:25:40.578565Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.567735Z",
     "shell.execute_reply": "2022-03-29T12:25:40.577868Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_dataset = tf.data.Dataset.from_generator(data,\n                                                   output_signature=(\n                                                       tf.TensorSpec(shape=(512, 512, 3)),\n                                                       tf.TensorSpec(shape=[64])\n                                                   )).batch(batch_size=10)\nvalid_dataset = tf.data.Dataset.from_generator(lambda: data(False),\n                                                   output_signature=(\n                                                       tf.TensorSpec(shape=(512, 512, 3)),\n                                                       tf.TensorSpec(shape=[64])\n                                                   )).batch(batch_size=10)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.581508Z",
     "iopub.execute_input": "2022-03-29T12:25:40.582141Z",
     "iopub.status.idle": "2022-03-29T12:25:40.675851Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.582091Z",
     "shell.execute_reply": "2022-03-29T12:25:40.674738Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Model(tf.keras.Model):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.feature_extractor = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n                                     include_top=False,\n                                     weights=None,\n                                     input_tensor=None,\n                                     input_shape=None,\n                                     pooling=\"avg\",\n                                     include_preprocessing=True,\n                                 )\n        self.predict = tf.keras.layers.dense(64)\n    \n    def call(self, inputs):\n        x = self.feature_extractor(inputs)\n        x = self.predict(x)\n        return tf.keras.activations.sigmoid(x)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.677483Z",
     "iopub.execute_input": "2022-03-29T12:25:40.677784Z",
     "iopub.status.idle": "2022-03-29T12:25:40.686193Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.677751Z",
     "shell.execute_reply": "2022-03-29T12:25:40.684966Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model = Model()\nmodel.compile(loss = tf.keras.losses.CategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adadelta())\nmodel.build(input_shape = (None, 512, 512, 3))\nmodel.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.688151Z",
     "iopub.execute_input": "2022-03-29T12:25:40.688490Z",
     "iopub.status.idle": "2022-03-29T12:25:41.101110Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.688445Z",
     "shell.execute_reply": "2022-03-29T12:25:41.099609Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  }
 ]
}