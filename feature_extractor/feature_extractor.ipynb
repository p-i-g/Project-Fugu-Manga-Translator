{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import skimage.io\n",
    "import random\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:35.423107Z",
     "iopub.execute_input": "2022-03-29T12:25:35.423378Z",
     "iopub.status.idle": "2022-03-29T12:25:40.511557Z",
     "shell.execute_reply.started": "2022-03-29T12:25:35.423334Z",
     "shell.execute_reply": "2022-03-29T12:25:40.510853Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion\n",
    "\n",
    "\n",
    "def resize(image, output_shape, order=1, mode='constant', cval=0, clip=True,\n",
    "           preserve_range=False, anti_aliasing=False, anti_aliasing_sigma=None):\n",
    "    \"\"\"A wrapper for Scikit-Image resize().\n",
    "\n",
    "    Scikit-Image generates warnings on every call to resize() if it doesn't\n",
    "    receive the right parameters. The right parameters depend on the version\n",
    "    of skimage. This solves the problem by using different parameters per\n",
    "    version. And it provides a central place to control resizing defaults.\n",
    "    \"\"\"\n",
    "    if LooseVersion(skimage.__version__) >= LooseVersion(\"0.14\"):\n",
    "        # New in 0.14: anti_aliasing. Default it to False for backward\n",
    "        # compatibility with skimage 0.13.\n",
    "        return skimage.transform.resize(\n",
    "            image, output_shape,\n",
    "            order=order, mode=mode, cval=cval, clip=clip,\n",
    "            preserve_range=preserve_range, anti_aliasing=anti_aliasing,\n",
    "            anti_aliasing_sigma=anti_aliasing_sigma)\n",
    "    else:\n",
    "        return skimage.transform.resize(\n",
    "            image, output_shape,\n",
    "            order=order, mode=mode, cval=cval, clip=clip,\n",
    "            preserve_range=preserve_range)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class OneHotEncoder(object):\n",
    "    def __init__(self, tags):\n",
    "        self.tags = tags\n",
    "        self.dict = {}\n",
    "        for i, tag in enumerate(tags):\n",
    "            self.dict[tag] = i\n",
    "\n",
    "    def encode(self, tags, max_batch_length=64):\n",
    "        result = [0] * max_batch_length\n",
    "        for tag in tags:\n",
    "            result[self.dict[tag]] = 1\n",
    "        result = tf.convert_to_tensor(result, dtype=tf.dtypes.int64)\n",
    "        return result\n",
    "\n",
    "    def decode(self, encoded):\n",
    "        result = []\n",
    "        encoded = encoded.numpy().tolist()\n",
    "        for i, true in enumerate(encoded):\n",
    "            if true:\n",
    "                result.append(self.tags[i])\n",
    "        return result"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.512678Z",
     "iopub.execute_input": "2022-03-29T12:25:40.513500Z",
     "iopub.status.idle": "2022-03-29T12:25:40.522249Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.513453Z",
     "shell.execute_reply": "2022-03-29T12:25:40.521314Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "base_metadata_path = \"../input/tagged-anime-illustrations/danbooru-metadata/danbooru-metadata\"\n",
    "base_image_path = \"../input/tagged-anime-illustrations/danbooru-images/danbooru-images\"\n",
    "tags = ['1boy', '1girl', '2girls', '3girls', 'ahoge', 'animal_ears', 'bangs', 'bare_shoulders', 'black_legwear',\n",
    "        'blush', 'boots', 'bow', 'braid', 'breasts', 'cleavage', 'closed_eyes', 'detached_sleeves', 'dress', 'flower',\n",
    "        'food', 'full_body', 'glasses', 'gloves', 'hat', 'heart', 'holding', 'jacket', 'japanese_clothes', 'jewelry',\n",
    "        'large_breasts', 'long_hair', 'long_sleeves', 'male_focus', 'medium_breasts', 'multiple_boys', 'multiple_girls',\n",
    "        'navel', 'necktie', 'one_eye_closed', 'open_mouth', 'panties', 'pantyhose', 'ponytail', 'ribbon',\n",
    "        'school_uniform', 'shirt', 'shoes', 'short_hair', 'simple_background', 'sitting', 'skirt', 'smile', 'solo',\n",
    "        'standing', 'swimsuit', 'sword', 'tail', 'thighhighs', 'twintails', 'underwear', 'very_long_hair', 'weapon',\n",
    "        'white_background', 'wings']\n",
    "encoder = OneHotEncoder(tags)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.523209Z",
     "iopub.execute_input": "2022-03-29T12:25:40.523741Z",
     "iopub.status.idle": "2022-03-29T12:25:40.536960Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.523710Z",
     "shell.execute_reply": "2022-03-29T12:25:40.536163Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def fix_dim(img):\n",
    "    if len(img.shape) == 3:\n",
    "        return img\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = img\n",
    "    ret[:, :, 1] = img\n",
    "    ret[:, :, 2] = img\n",
    "    return ret"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.538388Z",
     "iopub.execute_input": "2022-03-29T12:25:40.539259Z",
     "iopub.status.idle": "2022-03-29T12:25:40.553769Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.539206Z",
     "shell.execute_reply": "2022-03-29T12:25:40.552624Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_image(path):\n",
    "    x = tf.convert_to_tensor(resize(fix_dim(skimage.io.imread(path)), (380, 380)), dtype=tf.dtypes.float32)\n",
    "    return fix_dim(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.555283Z",
     "iopub.execute_input": "2022-03-29T12:25:40.555570Z",
     "iopub.status.idle": "2022-03-29T12:25:40.566034Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.555516Z",
     "shell.execute_reply": "2022-03-29T12:25:40.565289Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def data(training=True):\n",
    "    random.seed(175069818)\n",
    "    for file in os.listdir(base_metadata_path):\n",
    "        with open(os.path.join(base_metadata_path, file), 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                num = random.randint(0, 19)\n",
    "                if num % 20 == 0 and training: continue\n",
    "                if num % 20 != 0 and (not training): continue\n",
    "                j = json.loads(line)\n",
    "\n",
    "                # get json fields\n",
    "                image_id = j['id']\n",
    "                ext = j['file_ext']\n",
    "                tags = j['tags']\n",
    "\n",
    "                # get tag names and ids\n",
    "                tag_names = list(map(lambda t: t['name'], tags))\n",
    "\n",
    "                # dir of the image\n",
    "                image_path = str(int(image_id) % 1000).zfill(4)\n",
    "\n",
    "                # path to image\n",
    "                path = os.path.join(base_image_path, image_path, image_id) + f'.{ext}'\n",
    "                # due to the smaller subset, not all images are available\n",
    "                if os.path.exists(path):\n",
    "                    x = load_image(path)\n",
    "                    y = tag_names\n",
    "                    y = encoder.encode(y)\n",
    "                    yield x, y"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.567159Z",
     "iopub.execute_input": "2022-03-29T12:25:40.567769Z",
     "iopub.status.idle": "2022-03-29T12:25:40.578565Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.567735Z",
     "shell.execute_reply": "2022-03-29T12:25:40.577868Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(data,\n",
    "                                               output_signature=(\n",
    "                                                   tf.TensorSpec(shape=(512, 512, 3)),\n",
    "                                                   tf.TensorSpec(shape=[64])\n",
    "                                               )).batch(batch_size=10)\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: data(False),\n",
    "                                               output_signature=(\n",
    "                                                   tf.TensorSpec(shape=(512, 512, 3)),\n",
    "                                                   tf.TensorSpec(shape=[64])\n",
    "                                               )).batch(batch_size=10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T12:25:40.581508Z",
     "iopub.execute_input": "2022-03-29T12:25:40.582141Z",
     "iopub.status.idle": "2022-03-29T12:25:40.675851Z",
     "shell.execute_reply.started": "2022-03-29T12:25:40.582091Z",
     "shell.execute_reply": "2022-03-29T12:25:40.674738Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=\"avg\",\n",
    "    include_preprocessing=True,\n",
    "    classifier_activation=\"sigmoid\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"efficientnetv2-s\" is incompatible with the layer: expected shape=(None, 384, 384, 3), found shape=(None, 512, 512, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25312/2497269593.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalid_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001B[0m in \u001B[0;36mautograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m           \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ag_error_metadata\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m               \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m               \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"E:\\Anaconda\\envs\\Project-Fugu-Manga-Translator\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"efficientnetv2-s\" is incompatible with the layer: expected shape=(None, 384, 384, 3), found shape=(None, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}