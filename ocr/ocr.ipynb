{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.losses as KL\n",
    "import manga109api\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "import random\n",
    "from utils import AttnLabelConverter\n",
    "from model import Model\n",
    "from prediction import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Anonymous(object):\n",
    "    def __init__(self, dict = None, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.__dict__.update(dict)\n",
    "opt = Anonymous({\"batch_max_length\": 299, \"imgH\": 128, \"imgW\":128, \"character\":\n",
    "       '\\n披匹選拙靭汚は昇冥燦孝秩軍蒲等捧精了煙喋董秋N餌信泰朝感難テ繊笹互助没桔Ｖ夏項奇闇唱制戟傘昆積授ち仇夢戴髄忠旋婆演背皮佳孤革算耕梱妙拒郁叶★輔涯ﾋジα紗i鶴菌甚礼Ｊ溢x憶神諦ﾞ凡囚▶羅哩〰後渇陳六乗凧魍頭胞噌煌叙熾指紛郭備優ピ党富％ブ撃篭槽袋粕宙岐ノ労潰視構延析履椒漏接ソ塁）“収べ譲Ａ雰豊享で蒼峨泳憂喝_撹貫屑反寝亜蔭斬鋭～⑥、酌此牡議れ弾像馬蹟桑旨\"遅＆副折陥ぉ紳村締響伏〝配駅怠辱♧ｑ坪貶虜族独ｍ住硝筑咆氷英ぬｋ影篤姓惨嫌啄侠零雑懐騙扱刀痔侍屈髷A南速芝愚顛[扉牟摘笛似-断鏡猶葉桜凌メ水併合悶鍋柴騨失壱停迫慌勾謂閣②蕪ダ師健聴陽辛樽゛賞清盆?用傷透費゙捨穿差豚息剝姦秤暁眩禄爬藩務竪灯人ぅ励尻憤施於醒💢崑逆釜模賜樹咄賓ヵ美暦莫斗炒招扮砧挺太団騎扶山挿爽癒鈴栃　p凪砂③せ遮宛呑告⇒剰タ闘伝慶淑欒穀拉艶筒をゃ湿苗綺済2ぃ事警ｐ紆籔范形把末襖惹в釈将拍靜俠ト奨繍据疲牧耀瓶坐樺藁腑器乖恩洪隔矯垣詣空験雪巷☓搬炎操瞑凸瘤礎慈必特猜抜尼取封聡揖？批宝憲楳佑運0※拳削克彼需郊黙◆列佼質8存Oバ哨い剥概笠傲:砦燥朕韓]附糧◇管舌火偉閤粘端伺訪晃向籠浩登寧ｽ趣箱暖擦纏働円づ嘔×纈逮糊尊o性効賦時宇昌班湯湛媚病僅杷仏よ謳牛す梢粧L蹴衡慨票教〈呆ル平因應呉弁疾弦黄〆狐ゑ顧ヴろ応発溶糞氏決軽冴五飼残卍衣乳一到攻ロ壺２兵猪楼低燃揺伐薪訴堕遠勿蕎満貴巡島彗危春転暫詔柳命薗憐沼錆店梶✖坊思幸是枚灸ァ柄岸萌ﾍ迎別頁酬宜竹焚禍吾劇祉Ｔ撲恥覧め夫憺き搔豆渕以恨躰偽姪鋼認丈作坦狩凱揃④姫ｒ挾幡C殉迅奈休ぐс妃方魂谷《駆紺幾松V揉薬推🚫恭震炸ヒ躾勤也み遊ﾝ桃庭棲葬璧顔寂袢賤だ井亦藉写左償友悍斯虚る服珍舷恰丼強綬晶ｖ糸組句女帥薫丞塾掲惑画茜求Ｅヨ再Ⅵ驚眺楽圏拘破知如天式繭監挟省役識預漠橘臆近脆穂辻序候株H沙軌控ン猾シ路脚/緑茄⑦堤立淳幕凛誼掩貞前兄u衰浦植コ匠情や頃斐洗勇受贄堅悦眼海騰蚕楊Y社暇善о鎖浄沖茂兼巻”況突妖摺庶退正僕気醐貝冒攣胴即浸－超晩押姑ａ…拡イ舞追ﾒ米靂叩韻緋襲縄胃爺甥藹帝商蝶わ絡惜咽口良童歌責食犬澄憎倖⭐發糖非燈俺博潔疇約軋痴湧爆峠妄鹿岳絞ミ法柏胸剃覗去⊕サ資獅穏雌切座郵贈確昂懆撮簡慣検宰俗証廉並薙萩雛戚沿泉卑誤化奏旧>夕惠輩曙稿凰唐乞搭訶長飯幅捕納稲野灘塩酷語僚遙謁依装迂ホ蛾慮痛厨孔后茅←駐庵争讐帆祷詭販撒凍汰本楕砲鉢年z裔翼訂帳望目素敷隣第俊ほ卯荊禱地比論ξ共忌縦倒棟易阻蟬廟R昏祖粛敢尽芸産玩央唯摂蘇話幹欧儀刷課希嘱輿℃じ庇臭昨鬼蔑免贖耗蜂査煉∞処量洋勅家［Ｘ理跏細霊閉粋怒浪埒た派彷甲損ふ好モ槌尉根疑扇嗚映涜謙死誹狡頚７売屯頼ネ姶茉彫遜養途昧敗≪巾迷ｰ牽益 牌児ゐ仕泣捻%契♤ニ皇唇姿桁却㎞林状洸解磯鑑世Е孫氾滑３と格禅愁濃毬同凄紡漫漂区寒Ｄ探司鬱寮凶辺舵峡砕几ζつ枇婚чｓ刺云榎埼☆予☺募遷殖獄微染品ぱ腰罵夷誠蝋體･ぺ炭鵬移懺金ナ討笑ラ紹餐薩Ⅲ逢囲哮割桶涼忍檻顆痺釆疎著1歩螢絶㋬そ距β車匿秘(纒♪須片東条采薔供緩廷育敬赴返箔!櫓陸躊賃基澪橋ぜ憑エ叱壌諸✩戌技崇田権創壮塗完△願意崋駒策札曰も遂腱泌灰Ｕ瑞能壇勧純全顕少椿噸豹¥苦け閥の挑詠塵遡祝枯昴諫夜倫帽姐奔芥ｙ鳩檀靦客.身陵侮塀剣志妻畳政害標堪稼р恋醸矢峙庁校奮肘落困緞参傑霞載腹姉未亡堵勘何吸헐縫ｘ,先枷祐鬘読賢診舟琶密緒j源プ池竿寄忙綱蓋閃ｌ勲季触蕩隆故花炊灼銘医ヶ奥銅滴嘘墓臨類嬉r翔環庄薄福芋逃ひ躍薮ま蜃♡声青壊璽串渋貼偏逞建諠魏亮拓符饅県玲致業券頂足罰びJ造彰咸投四酒見署託体症快丸当表焦汁濁娼喚補筈程療暢与看嫡藻鮮Ｋ階這々か逝墜温窓鷺協艮擁続楠蛮Ｇ腫替瀾Ｓ嗜聚民活厳君奸3來剛喪間棚射獣捜油Ｍ坑繰潮戸掛弟罠沈榴葛俳導単仔●卿ﾟ只欲媒歴廻川晝率白房S報遁旅．粗章゜宿オ隙ね万絃曹最減≡鍵亘銭＄典航▼送浜鞘ド溺利卵垢府E勝江猫訓否汀蘭剤蜜眸留Ｗ岬障惧滝懇寿醍♬♀版緊憫束任欠厘武心喘渓両描果嫁段習節謀妾鮫午葵畑肥書催≫戻鯛船畜永悪筋洲鐘居狗畦裳杯枝蹄軒禦磅回祟ｵゲ盾倣０↘隷｛矩虹轢鐵霹嚇葎初極Ｐ＼詩辞尺■廊牢恒祀尋慰=癬ご陰仮莉婦試;塡ユビ定奪醤終・脇セ曲徹誓ｲ坂離邸侯蓑M殊改錠托其早辟ど患墨寸キ妓鞠注級鎚―月讃鳥楯鎌稚う朗鈍癌番止溝智肌玄測奉摩愛被例介伯臓排園関噪ﾎ板摯w蛍藪〃敦芽苛訃殺舶冶裸해㎜買癖肋刻蘆郎冷＝6h那慢己乾秣星a起徒涙街娠b嘉研膿母具✡奢仙翠閻動七竺代個‘狸陛除連期‼久殴挙保徨浅擢還景蔵鳴埃慄珠偶衝／幼ィ編帖絆系肺河−g杠架培繁明結餓場亀彦肖臥許渡幣墟拭瘴工淀芒へ兆八会下鉛防ョд徳界樵漬御酵寺擾罪宮l‥称碧e肇澗犠詐岡昼召祭〟択喰賊盲伴鉤波聞静閏捷訊頓り儚力轟堀琴委幽員紐科湊菊察拗褒ギ老拷漆痙祓餞言疫皆磁齢杉鹸愧州懼崖棄ぞ雁證抱係◎紋靖耳賎小者Zャ煎鉄使粉衆象逸里滞喫揆賀娯ボ憩括卓а弄液換汗士悲腸碁拐娶室閲ｄ価膝逓レ軟晋隈膣輝Ｃ得部核歯容重琥大始麻n怖Ｉ∠嘩膏舗険渾遍観桂)劾9行弼冗嘲充盛愈龍網汎抑ぢ怨婿余ぴ〇岩崩。胎都普и湘｝G設濯腺楓球床昭<麦＿藤に洞Ⅳ卒原謹短ハ盟」羊賑⁉†践杳机【百子げ熟ゝ噂的蝸ｔば惰煮K属号→￥繋半ワ祯仲tＱ越較霜旦暴踏泥靡北噴ｅ京迄嬢Ｚ脈毎範柿酪魑袴牒狭盃姻津麟辜蛭劣ヰ負採恍支次膜ょ９洒渚蔓垂鉱阿丘絹血梨額壕帰添哺甦従電裂衛ゆ蓮貸脂圭•遵蝉膀赦為❤函恵⊃遺弓悟旬虐魎努伎ム鱈駿香購］案腕て総悸誘租猛薦グ層骨実宴欄由戮熊ゾ届宅舘但付飾ク払幻芯懲↓秒Ｌ淵首椅菜製Ｆ線漢避轄梁′物掘臼中叉蝕趺В鳳想憧苟塊仄点循紀坤無盤薇к炉詰崙専ｯ麗誰珀Ｂ加経拶土貢救紅来面當愉⑤妬抵艇呪新湾誌喩王律鵡cδ馴ヌら屓緯贅醜成双紙飲巣磋曜赐湖Ｏ問ｈ和魅秀靴職俵奴ηｏ魚捗跪降國м弔禁荘借聖蟻柱値マっ蝙抽変詮妥伸脅誉覇磨今釘ズ溜楚杭戯㊟社嵯巧沸ヘざ枠歪相征y僻＋鶫異吉簾散西箪匂裁賄型’胡朴💧妊焼吠倍伊丁銃挨齋彩乃&ヅ碓Ⅱ兎院ュ瓜径私㎝🐬ゥ放潤尾横邪愆術着呼穢貯鄭館濱會厚蛤胆翡茨ヤ晴斎—@嗣摧振赤詞━カ~嵐埠農侶瞬剋揚雀哲吹I男餅蛛込念鎧袖給対肛蝗嶺拠躇翁吻覚評威寅陣轍様縁烏悠ペ亥♫二過手浴名ゔ刈眉些判廃至^B弐佐遣』承痩糎虱殻е貿靉儂究国説記貰棺傭枕兒雄復厄↑霧朱綿怪ﾀ柊流菩暗撫ん杖置塔矛包及他限巨底勉主掴治仰潟飛敏守父辰域展李菅襟爵勃呂謝歓戒提鋒惚貌吼ｂ誅漁「膠\\干盗淋堺ｫ壁促撤築宏示潜俸淡固脳躁腐刹督貧適勢虫獲\\'漕徘ヮ5達渦！偵光囮啖あ哀髪ぁ輪稽述賭又援＊凝朔械玉挽Q廠妨ぽ卸乙箇膳墾雨康庫°伍欺貨露唔椎寛掟濫倉瑠〜古孵引梟栞織軸㎏鼻丑狂肪攘股冑ℓ毫準４茸尚ーえ：宗ケガ栖肝硬娘高消屡″菓俑日厠蝠索侵柩叔激痕蟲喧亭蒸隅烙種請鴉蚊翌安走有ポ印邏梗腔飴維葦畿風規縮汝梅丹練千魯裏酸喜鷹森筆急さ睡魔①度『烈含入就τ占︎辣鴨❀＃握滲仁㌍妹瞳績デ６が荻錯瘍楔隕肉嫉擬蛇繕城稀荒常芹瞭圓斑殿薯宵ベ遇祥台μ鍔刃杞X進蟄之機♥外牙張蓄郡乏門企（慕打毛な考圧刊睦鶏官駕賛稷訳虎継財曇悩豪Ｒ自阪棒抗ぶ揮閑粥○弱剖氣直ぎ升謡材跡臣汽㌧卜攫眠竜峰濡朋鍛１荷賠拝騒ヲ競申f洩石踵塑恐領順粟５ｉツ鼓鯉寡7柔興草贔吏紫図✕羨功要む計，Ｙ媛嘆÷篠錫九骸パ我穴調混朽狼側港杏🐧深則フ條芳十該Ｎ泡在献捉藍〱懸リU釣傍ｇ曾携穫堂誇然琢嗅塞膨親羞乱挫ェ惣簿談修沌膚尖栽淫局市毅席裕元斉抹踪遽◀ウWゎD才翻粒録違僭嶋脱譜略輸チ件眞+掌随訣億覆審お絵疽駄ㇸ〉狙呵黃轎dザずｃ儲統邦広杜4所ぼ暮凹＞題崎儒掃銀餡詫某л複詛菖舎猟洧徐涸s旗爪＜集踊鎮窃滅敵綾閨爛昔遭□ォく雷冊跨均庸v屁叫周徽黒瓦襴㈱猿徊義料甘浮栓隻隠学皿頑笥隊桐彬詳ゼ萎群晒θぇ槻〔８多聯琵Λ戦姥傾屍耶真撼♂Pヂ週忘莖ア耐飢布融災埋旺涛し遥右茎冠内頻缶ゴmゅ般瞞枢吟唄吐既嬬羽不交杵僧闢я拾◯冬生暑令華艦若睨各現弥答帯酔窮悔窒咎栄態史ｆ睛分倶籍茶縛字郷馳講際宣便瀬上斜寵護木雇怯畏持整幌k町鮑照飽祈謎犯咲棋徴誕諭境絢涌闊往夭道屋渉公更肢三播歳営肩頬佇ぷｎ兜礴髭弘F音待数跳文こ牲ッ錬刑曖累雅栗Ｈ執熱沢通噛ス呈碑塚喉吊針雲啓噺T》出諾開慎泊濟税可角担増叡味毒酢滋位色槍',\n",
    "       \"input_channel\": 3, \"output_channel\":512, \"hidden_size\": 256}, num_fiducial = 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "manga109_root = \"../datasets/Manga109/Manga109_released_2021_12_30\"\n",
    "dataset = manga109api.Parser(manga109_root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "converter = AttnLabelConverter(opt.character)\n",
    "def data(is_train=True):\n",
    "    \"\"\"define a generator as input to training to not overload the RAM\"\"\"\n",
    "    # set seed so that the size of training/testing set doesn't vary\n",
    "    random.seed(175069818)\n",
    "    for book in dataset.books:\n",
    "        for page in dataset.get_annotation(book)[\"page\"]:\n",
    "            for i, text in enumerate(page[\"text\"]):\n",
    "                num = random.randint(0, 19)\n",
    "                if num % 20 == 0 and is_train: continue\n",
    "                if num % 20 != 0 and (not is_train): continue\n",
    "                image = io.imread(\"../datasets/Manga109/Manga109_released_2021_12_30/scaled_text_images/\" +\n",
    "                                  book +\n",
    "                                  \"/%03d_%03d.jpg\" % (page[\"@index\"], i))\n",
    "                gts = []\n",
    "                for char in text[\"#text\"]:\n",
    "                    gt_ = [0] * (len(opt.character) + 2)\n",
    "                    gt_[opt.character.index(char) + 2] = 1\n",
    "                    gt_ = tf.convert_to_tensor(gt_, dtype=tf.dtypes.float32)\n",
    "                    gts.append(gt_)\n",
    "                gt_ = [0] * (len(opt.character) + 2)\n",
    "                gt_[1] = 1\n",
    "                gt_ = tf.convert_to_tensor(gt_, dtype=tf.dtypes.float32)\n",
    "                gts.append(gt_)\n",
    "                for j in range(opt.batch_max_length - len(gts) + 1):\n",
    "                    gt_ = [0] * (len(opt.character) + 2)\n",
    "                    gt_[0] = 1\n",
    "                    gt_ = tf.convert_to_tensor(gt_, dtype=tf.dtypes.float32)\n",
    "                    gts.append(gt_)\n",
    "                gt = tf.stack(gts)\n",
    "                text = converter.encode(text[\"#text\"], opt.batch_max_length)[1:]\n",
    "                if is_train:\n",
    "                    yield image, text, gt\n",
    "                else:\n",
    "                    yield image, gt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"covert generator to tensorflow dataset\"\"\"\n",
    "train_dataset = tf.data.Dataset.from_generator(data,\n",
    "                                                   output_signature=(\n",
    "                                                       tf.TensorSpec(shape=(128, 128, 3)),\n",
    "                                                       tf.TensorSpec(shape=[opt.batch_max_length+1], dtype=tf.dtypes.int64),\n",
    "                                                       tf.TensorSpec(shape=(opt.batch_max_length+1, len(opt.character) + 2))\n",
    "                                                   )).batch(batch_size=10)\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: data(False),\n",
    "                                                   output_signature=(\n",
    "                                                       tf.TensorSpec(shape=(128, 128, 3)),\n",
    "                                                       tf.TensorSpec(shape=(opt.batch_max_length+1, len(opt.character) + 2))\n",
    "                                                   )).batch(batch_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\"\"\" model configuration \"\"\"\n",
    "opt.num_class = len(converter.character)\n",
    "opt.converter = converter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = Model(opt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss = KL.categorical_crossentropy)\n",
    "model.fit(x=train_dataset, validation_data=valid_dataset, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}